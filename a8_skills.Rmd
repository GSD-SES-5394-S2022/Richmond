---
title: "Skills for Analysis Assignment 8"
author: "GSD SES 5394"
date: "Spring 2022"
output: 
  rmdformats::material
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Overview

The following skills will be useful for Analysis Assignment 8. This is not a complete list of everything you will need to do to complete the assignment (and you might choose to complete the assignment without using some of the skills covered here); but it includes an overview of skills that you will not have encountered in prior assignments. 

# Required packages

The skills in this tutorial draw on the `here` package, the `tidyverse` package(s), and the `sf` package, which are all familiar to you now. You will also need the `survey` and `srvyr` packages to calculate average trip lengths from NHTS data, the `od` package for visualizing desire lines, and the `scenRios` package, which you may have used for Assignment 4. Regardless of whether you've used it before, you'll need to reinstall it to get the `grvty_balancing()` function. Refer to the [Assignment 4 skills page](https://gsd-ses-5394-s2022.github.io/Richmond/a4_skills.html){target="_blank"} to see how to install the `scenRios` package from GitHub.

```{r, warning=FALSE, message=FALSE, results='hide'}
library(here)
library(tidyverse)
library(sf)
library(survey)
library(srvyr)
library(od)
library(ggspatial)
library(scenRios)
```

# Load trip generation data and skims

You'll need the numbers of trips by trip purpose that you generated for Assignment 7 and the travel time skims you generated for assignment 4.

```{r}
zones <- here("existing",
              "data",
              "zone_data.csv") %>%
  read_csv(show_col_types = FALSE)

skims <- here("existing",
              "data",
              "skims.csv") %>%
  read_csv(show_col_types = FALSE)
```

# Calculate average travel time by trip purpose

I'll get the average travel time by trip purpose from the NHTS. First I download the data (if you have it saved on your computer from a previous assignment, you can also just load it from wherever you saved it before).

```{r, message=FALSE, warning=FALSE, results='hide'}
temp <- tempfile()
download.file("https://nhts.ornl.gov/assets/2016/download/csv.zip", temp)

trips <- read_csv(unz(temp, "trippub.csv"), 
                      show_col_types = FALSE) %>%
  filter(HH_CBSA == "15380")

unlink(temp)
```

Then I create a variable that specifies the trip purpose (as you did for Assignment 7).

```{r}
trips <- trips %>%
  mutate(home_based = case_when(WHYTO == "01" ~ TRUE,
                                WHYTO == "02" ~ TRUE,
                                WHYFROM == "01" ~ TRUE,
                                WHYFROM == "02" ~ TRUE,
                                TRUE ~ FALSE)) %>%
  mutate(work = ifelse(WHYTO == "03" | WHYFROM == "03", TRUE, FALSE)) %>%
  mutate(purpose = case_when(home_based & work ~ "HBW",
                            home_based ~ "HBO",
                            TRUE ~ "NHB"))
```


Then I create a survey object and calculate the average travel time by trip purpose.

```{r}
trips_svy <- trips %>%
  as_survey(weights = WTTRDFIN)

ttime_by_purpose <- trips_svy %>%
  group_by(purpose) %>%
  summarise(avg_time = survey_mean(TRVLCMIN))

ttime_by_purpose
```

# Calculate minumum travel time across all modes

I suggest using the minimum travel time across all modes as the basis for trip distribution (this will usually be the drive time, but might not be in some cases). The `pmin()` calculates the minimum value across columns in a data frame (which is different from `min()` which will give you the minimum single value within one or more columns).

```{r}
skims <- skims %>%
  mutate(min_time = pmin(transit_time, 
                         car_time,
                         bike_time,
                         walk_time,
                         na.rm = TRUE)) 
```


# Calculate friction factors

You have some options on which function to use to calculate your friction factors. [NCHRP 716](https://www.trb.org/Publications/Blurbs/167055.aspx){target} lists three possibilities (see page 45).

## Exponential function 

The exponential function is:

$F_{ijp} = e^{-m_pt_{ij}}$

where $F_{ij}$ is the friction factor for trips with purpose p between zone i and zone j, $t_{ij}$ is the the travel time from zone i to zone j, and reasonable value for _m_ would be the mean travel time for all trips with purpose p in the region. 

Here, I'll calculate the friction factors for HBO trips using an exponential function.

```{r}
m_HBO <- ttime_by_purpose$avg_time[ttime_by_purpose$purpose == "HBO"]

skims <- skims %>%
  mutate(F_HBO = exp(-1 * m_HBO * min_time)) 
```

## Power function

The power function is:

$F_{ijp} = t_{ij}^{-a}$

where $F_{ij}$ is the friction factor for trips with purpose p between zone i and zone j, $t_{ij}$ is the the travel time from zone i to zone j, and a common value for a would be 2 (for consistency with the Law of Gravity, which is the inspiration for the gravity model). 

Here, I'll calculate the friction factors for NHB trips using a power function.

```{r}
skims <- skims %>%
  mutate(F_NHB = min_time^-2) 
```

## Gamma function

The Gamma function is also called the combined function, since it's just the product of the power function and the exponential function. It can be written as:

$F_{ijp} = t_{ij}^{b}e^{ct_{ij}}$

where $F_{ij}$ is the friction factor for trips with purpose p between zone i and zone j, $t_{ij}$ is the the travel time from zone i to zone j, and b and c are calibration parameters. Table 4.5 of NCHRP 716 (reproduced below for your convenience) offers example values for b and c used by seven MPOs that use a gamma function for the trip distribution step of their regional travel demand model. 

![](images/NCHRP-4-5.png)

All of you are working in study areas with more than a million people, which qualifies as a Large MPO, so choosing values from Large MPO 1, 2, or 3 might be a reasonable starting point.

Here, I'll calculate the friction factors for HBW trips using a gamma function with parameters from Large MPO 1.

```{r}
skims <- skims %>%
  mutate(F_HBW = min_time^-0.503*exp(-0.078*min_time)) 
```

# Estimate travel flows

The number of trips between Zone i and Zone j is 

$T_{ij} = A_iO_iB_jD_jF_{ij}$, where 

* $T_{ij}$ is the number of trips between i and j
* $O_i$ is the number of origins (or productions) at Zone i
* $D_j$ is the number of destinations (or attractions) at Zone j
* $F_{ij}$ is the friction factor between i and j
* $A_i$ and $B_j$ are balancing factors, where:

$A_i = \frac{1}{\sum_jB_jD_jF_{ij}}$ and
$B_j = \frac{1}{\sum_iA_iO_iF_{ij}}$

Since the value of $A_i$ depends of the value of $B_j$ and the value of $B_j$ depends of the value of $A_i$, you'll need to find these values iteratively. The `grvty_balancing()` function takes care of this for you. It takes the following arguments:

* *od_zones*: A data frame with the number of origins and destinations (or productions and attractions) in each zone,
* *friction*: A data frame with a friction factor for each origin-destination pair,
* *zone_id*: The name of a column in `od_zones` containing an ID number (or string) for each zone,
* *zone_o*: The name of a column in `od_zones` containing the number of origins (or productions) in each zone,
* *zone_d*: The name of a column in `od_zones` containing the number of destinations (or attractions) in each zone,
* *friction_o_id*: The name of a column in `friction` containing the ID for the origin/production zone,
* *friction_d_id*: The name of a column in `friction` containing the ID for the destination/attraction zone,
* *friction_factor*: The name of a column in `friction` containing the friction factor for each origin-destination (or production-attraction) pair,
* *tolerance*: The minimum acceptable tolerance for trip estimates. In the example below, I'm setting this to 5, meaning I'll accept a set of flows where the total number of productions and attractions are within 5 trips of what I estimated in the trip generation step.
* *max_iter*: The maximum number of iterations. In this example, I'm setting this to 50,000, so that if I don't achieve my desired tolerance within 50,000 iterations, I'll stop the process anyway. This will keep me from getting stuck in an endless loop if I set a very low tolerance than I can't achieve due to rounding error.

```{r}
HBO_dist <- grvty_balancing(od_zones = zones,
                            friction = skims,
                            zone_id = "GEOID",
                            zone_o = "hbo_prod",
                            zone_d = "hbo_attr_bal",
                            friction_o_id = "fromId",
                            friction_d_id = "toId",
                            friction_factor = "F_HBO",
                            tolerance = 5,
                            max_iter = 50000)
```

This returns a list of two data frames: `flows`, and `convergence`. 

`convergence` has three columns: 

* *iteration*: An iteration number,
* *max_o_diff*: The maximum difference between the number of origins given in `od_zones` and the number produced by the gravity model at a particular iterations,
* *max_d_diff*: The maximum difference between the number of destinations given in `od_zones` and the number produced by the gravity model at a particular iterations.

Here are the last few rows of `convergence`:

```{r}
tail(HBO_dist$convergence)
```

You can see here that in the 13,337th iteration, both the origins and destinations were within 5 trips of their targets, so grvty_balancing accepted those values.

`flows` has three columns:

* *o_id*: The ID of the origin/production zone,
* *d_id*: The ID of the destination/attraction zone, and
* *flow* : The number of trips between each origin/production and destination/attraction.

You can see here that the O-D (P-A) pairs in the first few rows of `flows` have no trips between them.

```{r}
head(HBO_dist$flows)
```

In fact, only 852 P-A pairs have non-zero HBO trips between them.

```{r}
table(HBO_dist$flows$flow > 0)
```

# Visualize convergence

It can be interesting to see what happened in the `grvty_balance()` function on the way to convergence. This is mostly for your own interest - a plot like this doesn't need to make its way into your report.

```{r}
convergence_points <- HBO_dist$convergence %>%
  mutate(max_diff = max_o_diff + max_d_diff) %>%
  mutate(which_max = ifelse(max_o_diff > max_d_diff, 
                            "Productions",
                            "Attractions"))

ggplot(convergence_points) +
  geom_line(aes(x = iteration, y = max_diff, lty = which_max)) +
  scale_y_continuous(name = "Maximum difference from target value",
                     trans = "log", 
                     breaks = breaks <- 10^seq(1,5, by=1),
                     labels = formatC(breaks, 
                                      big.mark = ",", 
                                      format = "f", 
                                      digits = 0)) +
  scale_x_continuous(name = "Iteration",
                     breaks = breaks <- seq(0, 14000, by=2000),
                     labels = formatC(breaks, 
                                      big.mark = ",", 
                                      format = "f", 
                                      digits = 0)) +
  scale_linetype(name = "") +
  theme_minimal()
```

# Map desire lines

Desire lines are straight lines connecting origins to destinations and are a useful way to visualize origin-destination data. Here's how you would create a map with desire lines for HBO trips.

```{r}
zone_boundaries <- here("zones",
              "boundaries.geojson") %>%
  st_read(quiet = TRUE)

desire_lines_HBO <- od_to_sf(HBO_dist$flows, zone_boundaries, silent = TRUE) %>%
  filter(flow > 0)

ggplot(desire_lines_HBO) +
  annotation_map_tile(type = "cartolight", zoom = 10, progress = "none") +
  geom_sf(aes(alpha = flow)) +
  theme_void()
```

That looks okay because there are so many O-D pairs with zero trips between them. You may find that you end up with a mess like this:

![](images/messy_flows.png)

In that case, it might be useful to only show desire lines to and from one specific zone. I can check to see which zone is attracting the most trips.

```{r}
big_attraction <- zones[zones$hbo_attr_bal == max(zones$hbo_attr_bal),]$GEOID

big_attraction
```

And then map the desire lines for trips attracted to that zone.

```{r}
desire_lines_one_zone <- desire_lines_HBO %>%
  filter(d_id == big_attraction)

ggplot(desire_lines_one_zone) +
  annotation_map_tile(type = "cartolight", zoom = 11, progress = "none") +
  geom_sf(aes(alpha = flow)) +
  theme_void()
```


# Compare calculated travel times to observed travel times

We previously calculated the average travel time for each trip purpose.

```{r}
ttime_by_purpose
```

We can also calculate the average travel time estimated by our gravity model.

```{r}
HBO_flows <- HBO_dist$flows %>%
  rename(fromId = o_id,
         toId = d_id,
         HBO_flow = flow)

skims <- skims %>%
  left_join(HBO_flows) %>%
  replace_na(list(HBO_flow = 0)) %>%
  mutate(total_time = HBO_flow * min_time)

HBO_mean_time <- sum(skims$total_time) / sum(skims$HBO_flow)

HBO_mean_time
```

Our gravity model generates a PA matrix for HBO trips with an average travel time of 8.8 minutes. Our calculations from NHTS data suggest an average travel time of 17.9 minutes. Experiment with different decay functions. You could choose an entirely different functional form (e.g. a gamma function instead of an exponential function) or fiddle around with the parameters on the function you're already using. See if you can narrow the gap between the predicted and observed average travel times.
